<!-- Abstract -->
<section class="paper-section static-card" id="abstract">
    <h2>1. Abstract</h2>
    <p>
        Current Large Language Models (LLMs) exhibit a critical modal disconnect: they possess vast semantic knowledge but lack the procedural grounding to respect the immutable laws of the physical world. Consequently, while these agents implicitly function as world models, their simulations often suffer from <strong>physical hallucinations</strong>â€”generating plans that are logically sound but physically unexecutable.
    </p>
    <p>
        To bridge this gap, we introduce <strong>WorldMind</strong>, a framework that autonomously constructs a symbolic <strong>World Knowledge Repository (WKR)</strong> by synthesizing environmental feedback. Specifically, it unifies <strong>Process Experience</strong> to enforce physical feasibility via prediction errors and <strong>Goal Experience</strong> to guide task optimality through successful trajectories. Experiments on EB-ALFRED and EB-Habitat demonstrate that WorldMind achieves superior performance compared to baselines with remarkable cross-model and cross-environment transferability.
    </p>
</section>
