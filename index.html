<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WorldMind: Aligning Agentic World Models via Knowledgeable Experience Learning</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&family=Source+Code+Pro&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: #2c3e50;
            --accent-color: #3498db;
            --bg-color: #ffffff;
            --text-color: #333333;
            --light-gray: #f8f9fa;
        }

        body {
            font-family: 'Roboto', sans-serif;
            color: var(--text-color);
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: var(--bg-color);
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            padding: 20px;
        }

        header {
            text-align: center;
            padding: 60px 0 40px;
        }

        h1 {
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 10px;
            color: var(--primary-color);
        }

        .authors {
            font-size: 1.2rem;
            color: #555;
            margin-bottom: 10px;
        }

        .affiliations {
            font-size: 1rem;
            color: #777;
            margin-bottom: 20px;
        }

        .link-block {
            display: flex;
            justify-content: center;
            gap: 15px;
            margin-top: 20px;
        }

        .btn {
            display: inline-flex;
            align-items: center;
            background-color: #333;
            color: #fff;
            padding: 8px 16px;
            border-radius: 20px;
            text-decoration: none;
            font-weight: 500;
            transition: background-color 0.3s;
        }

        .btn:hover {
            background-color: #555;
        }

        .btn svg {
            margin-right: 8px;
            fill: white;
            width: 16px;
            height: 16px;
        }

        section {
            margin-bottom: 60px;
        }

        h2 {
            font-size: 1.8rem;
            border-bottom: 2px solid var(--light-gray);
            padding-bottom: 10px;
            margin-bottom: 20px;
            color: var(--primary-color);
        }

        p {
            font-size: 1.1rem;
            text-align: justify;
            margin-bottom: 15px;
        }

        /* Visualization Section */
        #visualization {
            background-color: var(--light-gray);
            padding: 30px;
            border-radius: 10px;
            text-align: center;
        }

        .comparison-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-top: 20px;
            text-align: left;
        }

        .card {
            background: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.05);
        }

        .card-title {
            font-weight: bold;
            margin-bottom: 10px;
            display: block;
        }

        .card.failure { border-left: 5px solid #e74c3c; }
        .card.success { border-left: 5px solid #27ae60; }

        /* 图片样式 */
        .figure-img {
            max-width: 100%;
            height: auto;
            border-radius: 5px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
            margin: 20px 0;
        }

        .vis-caption {
            margin-top: 15px;
            font-style: italic;
            color: #666;
            text-align: center;
            display: block;
        }

        /* BibTeX */
        pre {
            background-color: #f4f4f4;
            padding: 20px;
            border-radius: 5px;
            overflow-x: auto;
            font-family: 'Source Code Pro', monospace;
            font-size: 0.9rem;
            border: 1px solid #ddd;
        }

        footer {
            text-align: center;
            padding: 40px 0;
            color: #888;
            font-size: 0.9rem;
        }
    </style>
</head>
<body>

    <div class="container">
        <header>
            <h1>WorldMind: Aligning Agentic World Models via Knowledgeable Experience Learning</h1>
            
            <div class="authors">
                <span>Anonymous Authors</span>
            </div>
            
            <div class="affiliations">
                <span>ACL 2026 Submission / Zhejiang University (ZJUNLP)</span>
            </div>

            <div class="link-block">
                <a href="#" class="btn">
                    <svg viewBox="0 0 24 24"><path d="M14 2H6c-1.1 0-1.99.9-1.99 2L4 20c0 1.1.89 2 1.99 2H18c1.1 0 2-.9 2-2V8l-6-6zm2 16H8v-2h8v2zm0-4H8v-2h8v2zm-3-5V3.5L18.5 9H13z"/></svg>
                    Paper
                </a>
                <a href="#" class="btn">
                    <svg viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>
                    Code
                </a>
                <a href="#" class="btn">
                    <svg viewBox="0 0 24 24"><path d="M20 6h-8l-2-2H4c-1.1 0-1.99.9-1.99 2L2 18c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V8c0-1.1-.9-2-2-2zm0 12H4V8h16v10z"/></svg>
                    Data
                </a>
            </div>
        </header>

        <section id="visualization">
            <h2>Visualizing the "Physical Hallucination" Problem</h2>
            [cite_start]<p>Large Language Models (LLMs) often generate plans that are logically sound but physically unexecutable—a phenomenon we term <strong>Physical Hallucination</strong>[cite: 30]. WorldMind aligns these models by learning from experience.</p>
            
            <div class="comparison-grid">
                <div class="card failure">
                    <span class="card-title" style="color:#e74c3c;">❌ Without WorldMind (Standard LLM)</span>
                    <p><strong>Goal:</strong> "Slice the bread."</p>
                    <p><strong>Plan:</strong><br>1. Walk to table.<br>2. Slice bread.</p>
                    [cite_start]<p><strong>Outcome:</strong> <span style="color:#e74c3c;">FAILURE.</span> The agent attempts to slice the object without holding a knife[cite: 92]. It understands the <em>why</em> but misses the physical <em>how</em>.</p>
                </div>
                
                <div class="card success">
                    <span class="card-title" style="color:#27ae60;">✅ With WorldMind (Our Method)</span>
                    <p><strong>Goal:</strong> "Slice the bread."</p>
                    <p><strong>Internal Simulation:</strong> <em>"Prediction Error: Cannot slice without tool."</em> -> <strong>Refinement.</strong></p>
                    <p><strong>Plan:</strong><br>1. Find knife.<br>2. Pick up knife.<br>3. Slice bread.</p>
                    <p><strong>Outcome:</strong> <span style="color:#27ae60;">SUCCESS.</span> Uses <strong>Process Experience</strong> to enforce physical constraints.</p>
                </div>
            </div>
            </section>

        <section id="abstract">
            <h2>Abstract</h2>
            <p>
                Current Large Language Models (LLMs) exhibit a critical modal disconnect: they possess vast semantic knowledge but lack the procedural grounding to respect the immutable laws of the physical world. [cite_start]Consequently, while these agents implicitly function as world models, their simulations often suffer from <strong>physical hallucinations</strong>—generating plans that are logically sound but physically unexecutable [cite: 29-30].
            </p>
            <p>
                To bridge this gap, we introduce <strong>WorldMind</strong>, a framework that autonomously constructs a symbolic <strong>World Knowledge Repository (WKR)</strong> by synthesizing environmental feedback. [cite_start]Specifically, it unifies <strong>Process Experience</strong> to enforce physical feasibility via prediction errors and <strong>Goal Experience</strong> to guide task optimality through successful trajectories [cite: 33-34]. [cite_start]Experiments on EB-ALFRED and EB-Habitat demonstrate that WorldMind achieves superior performance compared to baselines with remarkable cross-model and cross-environment transferability[cite: 35].
            </p>
        </section>

        <section id="method">
            <h2>The WorldMind Framework</h2>
            <p>
                WorldMind transforms autonomous agents into empirical learners. [cite_start]Instead of relying on resource-intensive training, it employs a <strong>Predict-Act-Verify</strong> loop to align the agent's internal world model with reality[cite: 230].
            </p>
            
            <img src="assets/framework.png" alt="WorldMind Framework Overview" class="figure-img">
            <p class="vis-caption">Figure 2: Overview of the WorldMind Framework. The agent autonomously constructs a World Knowledge Repository (WKR) by unifying Process Experience (from prediction errors) and Goal Experience (from successful trajectories).</p>

            <h3>Key Components</h3>
            <ul>
                <li>
                    <strong>Process Experience (Physical Boundaries):</strong> Derived from prediction errors (e.g., trying to open a cabinet while far away). [cite_start]The agent uses "Reflexion" to generate verbalized causal rules that prevent future physical hallucinations[cite: 219, 285].
                </li>
                <li>
                    <strong>Goal Experience (Procedural Shortcuts):</strong> Distilled from successful trajectories. [cite_start]These serve as heuristics to guide the policy search space towards optimal paths, ensuring efficient convergence[cite: 221, 288].
                </li>
            </ul>
        </section>

        <section id="results">
            <h2>Experimental Results</h2>
            <p>
                We evaluated WorldMind on <strong>EB-ALFRED</strong> and <strong>EB-Habitat</strong>. [cite_start]The framework consistently outperforms baselines (ReAct, BON, SimuRA, etc.) in both Success Rate (SR) and Goal-Conditioned Success (GC)[cite: 354].
            </p>

            <div style="overflow-x: auto;">
                <table style="width: 100%; border-collapse: collapse; margin: 20px 0; font-size: 0.95rem;">
                    <thead>
                        <tr style="background-color: #f8f9fa; border-bottom: 2px solid #ddd;">
                            <th style="padding: 12px; text-align: left;">Backbone</th>
                            <th style="padding: 12px; text-align: left;">Method</th>
                            <th style="padding: 12px; text-align: center;">EB-ALFRED (SR)</th>
                            <th style="padding: 12px; text-align: center;">EB-Habitat (SR)</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr style="border-bottom: 1px solid #eee;">
                            <td rowspan="2" style="padding: 12px;">GPT-3.5-turbo</td>
                            <td style="padding: 12px;">ReAct</td>
                            <td style="padding: 12px; text-align: center;">44.4%</td>
                            <td style="padding: 12px; text-align: center;">43.6%</td>
                        </tr>
                        <tr style="border-bottom: 1px solid #eee; background-color: #eef9f0;">
                            <td style="padding: 12px;"><strong>WorldMind (Ours)</strong></td>
                            <td style="padding: 12px; text-align: center;"><strong>48.0%</strong></td>
                            <td style="padding: 12px; text-align: center;"><strong>48.8%</strong></td>
                        </tr>
                        <tr style="border-bottom: 1px solid #eee;">
                            <td rowspan="2" style="padding: 12px;">GPT-4.1-mini</td>
                            <td style="padding: 12px;">ReAct</td>
                            <td style="padding: 12px; text-align: center;">41.6%</td>
                            <td style="padding: 12px; text-align: center;">41.6%</td>
                        </tr>
                        <tr style="background-color: #eef9f0;">
                            <td style="padding: 12px;"><strong>WorldMind (Ours)</strong></td>
                            <td style="padding: 12px; text-align: center;"><strong>50.0%</strong></td>
                            <td style="padding: 12px; text-align: center;"><strong>50.8%</strong></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            [cite_start]<p class="vis-caption">Table 1: Comparison of Success Rates. WorldMind achieves state-of-the-art performance by reducing physical hallucinations[cite: 334, 396].</p>
            
            <h3>Cross-Model Transferability</h3>
            <p>
                A key finding is that the experience learned by one model (e.g., GPT-4.1-mini) can be transferred to another (e.g., GPT-3.5-turbo), significantly improving the latter's performance. [cite_start]This confirms that the constructed world knowledge captures universal physical laws independent of the specific backbone model[cite: 111, 410].
            </p>
        </section>

        <section id="bibtex">
            <h2>BibTeX</h2>
            <pre><code>@inproceedings{anonymous2026worldmind,
  title={Aligning Agentic World Models via Knowledgeable Experience Learning},
  author={Anonymous Authors},
  booktitle={Proceedings of the 64th Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2026}
}</code></pre>
        </section>

    </div>

    <footer>
        <p>&copy; 2026 ZJUNLP. All rights reserved.<br>
        Template inspired by <a href="https://agentflow.stanford.edu/" target="_blank" style="color:#666;">AgentFlow</a>.</p>
    </footer>

</body>
</html>
